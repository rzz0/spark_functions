# spark_functions

## Pyspark

The purpose of this repository is to help beginner developers learn about pyspark.

In this repository it is possible to find some functions in pyspark that can be used in an Extract, Transform and Load (ETL) process in a pipeline developed for the Databricks data platform under the context of Delta Lake.

The functions were developed in pyspark and are separated by file, containing documentation in a very didactic way for learning and fixing knowledge.
